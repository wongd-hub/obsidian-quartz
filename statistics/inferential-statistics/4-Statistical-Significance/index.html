<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="#coursera-inferential-stats #statistics
Table of contents  [[#Inference for Other Estimators]] [[#Decision Errors]] [[#Significance vs. Confidence Level]] [[#Statistical vs. Practical Significance]]]  Inference for Other Estimators The methods we&rsquo;ve been learning can be applied to other estimators that have nearly-normal sampling distributions, which are listed here:"><meta property="og:title" content><meta property="og:description" content="#coursera-inferential-stats #statistics
Table of contents  [[#Inference for Other Estimators]] [[#Decision Errors]] [[#Significance vs. Confidence Level]] [[#Statistical vs. Practical Significance]]]  Inference for Other Estimators The methods we&rsquo;ve been learning can be applied to other estimators that have nearly-normal sampling distributions, which are listed here:"><meta property="og:type" content="website"><meta property="og:image" content="https://wongd-hub.github.io/obsidian-quartz/icon.png"><meta property="og:url" content="https://wongd-hub.github.io/obsidian-quartz/statistics/inferential-statistics/4-Statistical-Significance/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="#coursera-inferential-stats #statistics
Table of contents  [[#Inference for Other Estimators]] [[#Decision Errors]] [[#Significance vs. Confidence Level]] [[#Statistical vs. Practical Significance]]]  Inference for Other Estimators The methods we&rsquo;ve been learning can be applied to other estimators that have nearly-normal sampling distributions, which are listed here:"><meta name=twitter:image content="https://wongd-hub.github.io/obsidian-quartz/icon.png"><meta name=twitter:site content="_jzhao"><title>ðŸª´ Quartz 3.3</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://wongd-hub.github.io/obsidian-quartz//icon.png><link href=https://wongd-hub.github.io/obsidian-quartz/styles.19109a40042e9f0e72e952fda4442a34.min.css rel=stylesheet><link href=https://wongd-hub.github.io/obsidian-quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://wongd-hub.github.io/obsidian-quartz/js/darkmode.df266a900377a99b203da11b154c20ec.min.js></script>
<script src=https://wongd-hub.github.io/obsidian-quartz/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://wongd-hub.github.io/obsidian-quartz/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://wongd-hub.github.io/obsidian-quartz/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://wongd-hub.github.io/obsidian-quartz/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://wongd-hub.github.io/obsidian-quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://wongd-hub.github.io/obsidian-quartz/",fetchData=Promise.all([fetch("https://wongd-hub.github.io/obsidian-quartz/indices/linkIndex.dcd38a527bb7b7e8f37396f714007c80.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://wongd-hub.github.io/obsidian-quartz/indices/contentIndex.841af020902d76edc70c00cbb7bf1f3c.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://wongd-hub.github.io/obsidian-quartz",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://wongd-hub.github.io/obsidian-quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/wongd-hub.github.io\/obsidian-quartz\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=wongd-hub.github.io/obsidian-quartz src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://wongd-hub.github.io/obsidian-quartz/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://wongd-hub.github.io/obsidian-quartz/>ðŸª´ Quartz 3.3</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Jul 23, 2023
<a href=https://github.com/jackyzha0/quartz/tree/hugo/content/statistics/inferential-statistics/4%20Statistical%20Significance.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#table-of-contents>Table of contents</a></li><li><a href=#inference-for-other-estimators>Inference for Other Estimators</a><ol><li><a href=#unbiased-estimator>Unbiased estimator</a></li><li><a href=#decision-errors>Decision Errors</a></li></ol></li><li><a href=#significance-vs-confidence-level>Significance vs. Confidence Level</a></li><li><a href=#statistical-vs-practical-significance>Statistical vs. Practical Significance</a><ol><li></li></ol></li></ol></nav></details></aside><p>#coursera-inferential-stats #statistics</p><a href=#table-of-contents><h2 id=table-of-contents><span class=hanchor arialabel=Anchor># </span>Table of contents</h2></a><ol><li><a href=/obsidian-quartz#inference-for-other-estimators rel=noopener class=internal-link data-src=/obsidian-quartz></a></li><li><a href=/obsidian-quartz#decision-errors rel=noopener class=internal-link data-src=/obsidian-quartz></a></li><li><a href=/obsidian-quartz#significance-vs.-confidence-level rel=noopener class=internal-link data-src=/obsidian-quartz></a></li><li><a href=/obsidian-quartz#statistical-vs.-practical-significance rel=noopener class=internal-link data-src=/obsidian-quartz></a></li></ol><a href=#inference-for-other-estimators><h2 id=inference-for-other-estimators><span class=hanchor arialabel=Anchor># </span>Inference for Other Estimators</h2></a><p>The methods we&rsquo;ve been learning can be applied to other estimators that have nearly-normal sampling distributions, which are listed here:</p><ul><li>The sample mean ($\bar{x}$)</li><li>The difference between two sample means ($\bar{x}_1 - \bar{x}_2$)</li><li>Sample proportion ($\hat{p}$)</li><li>The difference between sample proportions ($\hat{p}_1 - \hat{p}_2$)</li></ul><a href=#unbiased-estimator><h3 id=unbiased-estimator><span class=hanchor arialabel=Anchor># </span>Unbiased estimator</h3></a><p>An important assumption about these point estimates is that they are unbiased - their sampling distribution is centred on the true population parameter it estimates. In other words, it does not naturally overor under-estimate the population parameter.</p><p>For nearly-normal estimators, the confidence interval equation remains $\text{point estimate} \pm z^*SE$; all we&rsquo;ll need to do is swap out the formula for the standard error of a different estimate.</p><p>We&rsquo;ll go through high level examples here using different standard errors, but we&rsquo;ll go into more detail on each of these later on.</p><a href=#example-1><h4 id=example-1><span class=hanchor arialabel=Anchor># </span>Example 1</h4></a><p>A 2010 Pew Research foundation poll indicates that among 1,099 college graduates, 33% watch the Daily Show. An American late-night TV Show. The standard error of this estimate is 0.014. We are asked to estimate the 95% confidence interval for the proportion of college graduates who watch The Daily Show.</p><p>We have a few pieces of information given to us:</p><ul><li>$n = 1,099$</li><li>$\hat{p} = 0.33$</li><li>$SE = 0.014$</li></ul><p>Now to our <a href=/obsidian-quartz/statistics/inferential-statistics/2-Confidence-Intervals rel=noopener class=internal-link data-src=/obsidian-quartz/statistics/inferential-statistics/2-Confidence-Intervals>confidence interval</a>: $\text{point estimate} \pm z^*SE \to 0.33 \pm 1.96 \times 0.014 \to \left(0.303, 0.357\right)$. The critical value is still 1.96 because this point estimate is still nearly-normal.</p><p>So we are 95% confident that between 30.3% and 35.7% of college graduates watch the Daily Show.</p><p>Since this estimator is unbiased, and again - the sampling distribution of this estimator is nearly-normal, we can calculate a z-score from which we can use to produce probabilities.</p><p>$$Z = \frac{\text{point estimate} - \text{null value}}{SE}$$</p><a href=#example-2><h4 id=example-2><span class=hanchor arialabel=Anchor># </span>Example 2</h4></a><p>The third national health and nutrition examination survey NHANES, collected body fat percentage and gender data from over 13,000 subjects in ages between 20 to 80. The average body fat percentage for the 6,580 men in the sample was 23.9%. And this value was 35% for the 7,021 women. The standard error for the difference between the average male and female body fat percentages was 0.114. Do these data provide convincing evidence that men and women have different average body fat percentages? You may assume that the distribution of the point estimate is nearly normal.</p><p>The population parameter we&rsquo;ll be estimating here is $\mu = \text{the average body fat percentage in the population}$; but across two different population groups.</p><ol><li><p>Set hypotheses: $H_0: \mu_{men} = \mu_{women}$, $H_A = \mu_{men} \neq \mu_{women}$</p></li><li><p>Calculate the point estimate: $\mu_{men} - \mu_{women} = 23.9 - 35 = -11.1$</p></li><li><p>Check conditions: We&rsquo;re told we can assume that the distribution is nearly normal; and since this is a nationwide survey we can assume that random sampling has been used and the observations are independent with respect to their body fat percentages.</p></li><li><p>Calculate the test statistic</p></li></ol><p>What does our sampling distribution centre on? It usually centres on the null hypothesis value of the population parameter, but the original form of our hypothesis does not have an asserted value. For tests between two population means, we can re-write the null hypothesis as:</p><p>$$H_0: \mu_{men} = \mu_{women} \to \mu_{men} - \mu_{women} = 0$$</p><p>So our sampling distribution here centres on 0, and our p-value is looking at the area under the CDF for values smaller than -11.1 and values greater than 11.1.</p><p>We do not yet know how to calculate the sample standard error of the difference between two population means, but we are given this value for now, so we can calculate our z-score as $Z = \frac{-11.1 - 0}{0.114} = -97.4$.</p><p>$$P(Z &lt; -97.4) + P(Z > 97.4) \approx 0$$</p><ol><li>What is the interpretation of this p-value in the context of the research question?</li></ol><p>There is strong evidence to reject the null hypothesis as the p-value is very small.</p><p>If there were truly no difference between the average body fat percentage of males and females, there would be a nearly 0% chance of getting data like or more extreme than ours. This is strong evidence to reject the hypothesis that there is no difference between males&rsquo; and females&rsquo; average body fat percentage.</p><a href=#decision-errors><h3 id=decision-errors><span class=hanchor arialabel=Anchor># </span>Decision Errors</h3></a><p><a href=/obsidian-quartz/statistics/inferential-statistics/3-Hypothesis-Testing rel=noopener class=internal-link data-src=/obsidian-quartz/statistics/inferential-statistics/3-Hypothesis-Testing>Hypothesis tests</a> are not flawless. Just like in court cases, innocent people can be incarcerated and guilty people can walk free. However, we have the tools necessary to quantify how often we make errors in statistics.</p><p>There are two main types of errors in hypothesis testing, the Type I and Type II errors - whose rates are inversely proportional.</p><ul><li>A Type I error is rejecting $H_0$ when $H_0$ is true<ul><li>This is like declaring the defendant guilty, when they are actually innocent</li></ul></li><li>A Type II error is failing to reject $H_0$ (i.e. rejecting $H_A$) when $H_A$ is true<ul><li>This is like declaring the defendant innocent, when they are actually guilty</li></ul></li></ul><p><a class="internal-link broken">Pasted image 20230712215313.png</a></p><p>We almost never know if the null or the alternative hypothesis are true with 100% certainty, but we need to consider all possibilities.</p><a href=#which-error-is-the-worst-to-make><h4 id=which-error-is-the-worst-to-make><span class=hanchor arialabel=Anchor># </span>Which error is the worst to make?</h4></a><p>This is a subjective question; however this brings to mind a quote by William Blackstone: &lsquo;better that 10 guilty persons escape, than one innocent person suffers&rsquo; (so a Type I is worse in this case).</p><a href=#type-i-errors><h4 id=type-i-errors><span class=hanchor arialabel=Anchor># </span>Type I errors</h4></a><ul><li><p>We reject $H_0$ when the p-value is below the significance level ($\alpha$), which is generally set at 5%.</p></li><li><p>This translates to us not wanting to reject $H_0$ incorrectly at least 5% of the time.</p></li></ul><p>Hence, the probability of making a Type I error is equal to $P\left(\text{Type I error} | H_0\text{ true}\right) = \alpha$; this is why we prefer smaller values of $\alpha$.</p><p>So how do we choose our $\alpha$?</p><ul><li><p>If a Type I error is especially dangerous or costly, set your significance level small to reduce the chance of a Type I error. By doing this, we demand very strong evidence that the null hypothesis is not the case in order to reject it.</p></li><li><p>However, if a Type II error is more costly, choose a larger significance level. This translates to us being cautious about failing to reject the null hypothesis when the null hypothesis is actually false.</p></li></ul><a href=#probabilities><h4 id=probabilities><span class=hanchor arialabel=Anchor># </span>Probabilities</h4></a><p><a class="internal-link broken">Pasted image 20230712215340.png</a></p><p>So:</p><ul><li><p>Given that the null hypothesis is true; you can either:</p><ul><li>Incorrectly reject the null hypothesis, with probability $\alpha$</li><li>Correctly retain the null hypothesis, with probability $1 - \alpha$</li></ul></li><li><p>Given that the alternative hypothesis is true; you can either:</p><ul><li>Incorrectly reject the alternative hypothesis, with probability $\beta$ (your Type II error)</li><li>Correctly reject the null hypothesis, with probability $1 - \beta$. This probability is referred to as the <em>power</em> of your test, and is the probability of correctly rejecting $H_0$ (given $H_A$ is true). Note that $\beta$ is not trivial to calculate.</li></ul></li></ul><p>Our goal is to keep both $\alpha$ and $\beta$ low at the same time; but we know that if we push one down, the other will shoot up. We generally want to find a good balance between the two.</p><a href=#type-ii-errors><h4 id=type-ii-errors><span class=hanchor arialabel=Anchor># </span>Type II errors</h4></a><ul><li><p>If the alternative hypothesis is actually true, what is the probability that we incorrectly reject it?</p></li><li><p>The answer is not obvious.</p><ul><li>If the true population mean is very close to the null hypothesis, then it will be hard to detect a difference and therefore reject $H_0$.</li><li>Clearly then, $\beta$ is dependent on the effect size ($\delta$) - which is the difference between the point estimate and the null value.</li></ul></li></ul><a href=#significance-vs-confidence-level><h2 id=significance-vs-confidence-level><span class=hanchor arialabel=Anchor># </span>Significance vs. Confidence Level</h2></a><p>So far we&rsquo;ve looked at two inferential techniques; <a href=/obsidian-quartz/statistics/inferential-statistics/2-Confidence-Intervals rel=noopener class=internal-link data-src=/obsidian-quartz/statistics/inferential-statistics/2-Confidence-Intervals>confidence intervals</a> and <a href=/obsidian-quartz/statistics/inferential-statistics/3-Hypothesis-Testing rel=noopener class=internal-link data-src=/obsidian-quartz/statistics/inferential-statistics/3-Hypothesis-Testing>hypothesis testing</a>. These methods are related and therefore it makes sense that their results will agree with each other if the confidence and significance levels are set the same.</p><p>Broadly speaking, we can say that the significance level and confidence level are complements of each other.</p><ul><li><p>The most commonly used significance level is 5%, whereas the most commonly used confidence level is 95%. These are complements.</p></li><li><p>However, whether this complement rule works or not depending on if we&rsquo;re doing a oneor two-sided hypothesis test.</p><ul><li>Recall that confidence intervals are centred on the mean value of the sampling distribution. This means that they will be most related to two-sided hypothesis tests that are also centered on the mean of the sampling distribution.</li></ul></li></ul><p>So:</p><ul><li>A two-sided hypothesis test with significance level of $\alpha$ is equivalent to a confidence interval with CL = $1 - \alpha$.</li><li>A one-sided hypothesis test with significance level of $\alpha$ is equivalent to a confidence interval with CL = $1 - 2 \times \alpha$.</li><li>If $H_0$ is rejected, a CI that agrees with its corresponding hypothesis test should <em>not include</em> the null value.</li><li>If $H_0$ is failed to be rejected, a CI that agrees with its corresponding HT should <em>include</em> the null value.</li></ul><a href=#statistical-vs-practical-significance><h2 id=statistical-vs-practical-significance><span class=hanchor arialabel=Anchor># </span>Statistical vs. Practical Significance</h2></a><p>While sometimes statistical and practical significance go hand in hand, that is not always the case.</p><p>Consider two scenarios, ceteris paribus, in which scenario will the p-value be lower if hypothesis tests were done with:</p><ol><li>We have n = 100; and,</li><li>We have n = 10,000</li></ol><p>We can see how this will affect the hypothesis test by considering the components that it affects first: the standard error.</p><p>$$Z = \frac{\bar{x} - \mu}{SE} = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{n}}}$$</p><p>As $n$ increases, the SE will decrease, driving up the Z-score which means that the point at which you measure your p-value on the distribution (i.e. your test statistic) is being moved further from the center; thus decreasing p-value.</p><a href=#another-example><h4 id=another-example><span class=hanchor arialabel=Anchor># </span>Another example</h4></a><p>Consider the following example where the sample statistic is very close to the null hypothesis parameter value:</p><p>$$H_0: \mu = 49.5, H_A: \mu > 49.5, \bar{x} = 50, s = 2$$</p><p>If n = 100; $Z = \frac{50-49.5}{\frac{2}{100}} = \frac{50-49.5}{\frac{2}{10}} = 0.5/0.2 = 2.5$</p><p>If n = 10,000; $Z = \frac{50-49.5}{\frac{2}{10000}} = \frac{50-49.5}{\frac{2}{100}} = 0.5/0.02 = 25$</p><p>Clearly this is a very large difference in outcomes. A z-score of 25 will have a near-zero p-value, and so is a highly statistically significant finding - however, is it practically significant?</p><p>When we&rsquo;re thinking about practical significance, we focus on the effect size ($\delta$), the difference between your po int estimate and your null value (the numerator in the z-score calculation). In both of the scenarios above, we have a relatively small $\delta$ which may not be practically significant, we are able to find a statistically significant result <em>simply by inflating our sample size</em>.</p><p>To recap:</p><ul><li><p>Real difference between the point estimate and the null value are easier to detect with larger sample sizes.</p></li><li><p>However, very large samples will result in statistical significance for very small effect sizes that may not be practically significant.</p></li><li><p>Usually to mitigate this, analysis is done a priori to the hypothesis test to determine what size sample should be gathered. This likely will include consultation with statisticians.</p></li></ul><p>&ldquo;To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination. He may be able to say what the experiment died of.&rdquo; - R.A. Fisher</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://wongd-hub.github.io/obsidian-quartz/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Jacky Zhao using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2023</p><ul><li><a href=https://wongd-hub.github.io/obsidian-quartz/>Home</a></li><li><a href=https://twitter.com/_jzhao>Twitter</a></li><li><a href=https://github.com/jackyzha0>GitHub</a></li></ul></footer></div></div></body></html>